{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.version\n",
    "from vit3 import MyViT\n",
    "import einops\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, RandomHorizontalFlip, RandomCrop\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "#from config import get_config, latest_weights_file_path\n",
    "#from train import get_model, get_ds, run_validation\n",
    "#from translate import translate\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torchaudio.datasets.SPEECHCOMMANDS(filepath, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "\n",
    "    # Display the image\n",
    "  img = mpimg.imread(image_path)\n",
    "  plt.imshow(img)\n",
    "  plt.axis('off')  # Turn off axis numbers and ticks\n",
    "  plt.show()\n",
    "  \n",
    "  preprocess = Compose([ \n",
    "    Compose([Resize(28), ToTensor()])\n",
    "    ])\n",
    "  \n",
    "\n",
    "  image = Image.open(image_path).convert('L')\n",
    "    # Add batch dimension\n",
    "  image = preprocess(image).unsqueeze(0).to(device)\n",
    "  \n",
    "  #print(image.shape)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Preprocess the image\n",
    "def preprocess_image2(image_path):\n",
    "\n",
    "  # Load sample image\n",
    "  test_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "  # Preview sample image\n",
    "  #plt.imshow(test_image, cmap='gray')\n",
    "\n",
    "  # Format Image\n",
    "  img_resized = cv2.resize(test_image, (28, 28), interpolation=cv2.INTER_LINEAR)\n",
    "  img_resized = cv2.bitwise_not(img_resized)\n",
    "\n",
    "\n",
    "\n",
    "  # Preview reformatted image\n",
    "  plt.imshow(img_resized, cmap='gray')\n",
    "  return ToTensor()(img_resized).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = MyViT((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10).to(device)\n",
    "\n",
    "saved_model.load_state_dict(torch.load('my_model3_2.pth', weights_only=True))\n",
    "\n",
    "saved_model.eval()\n",
    "\n",
    "image_path = r'images/Test8.jpg'\n",
    "image = preprocess_image2(image_path)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = saved_model(image)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "print(output)\n",
    "np_output = (output.cpu()).numpy()[0]\n",
    "\n",
    "j=0\n",
    "for i in np_output:\n",
    "  print(\"%s:\\t%.2f\" % (classes[j], i))\n",
    "  j += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
